"""
Module that wraps the top level API for the AFK Arena Roster Screenshot and
Hero processing

Calling detect_features assumes that the image processing environment has been
initialized and will parse apart an image and feed it into the various models
needed to detect AFK Arena Hero Features
"""
from typing import Dict, List, TYPE_CHECKING
import warnings

import cv2
import numpy as np

from detectron2.structures.instances import Instances
from pandas import DataFrame

import image_processing.globals as GV

from image_processing.load_images import display_image
from image_processing.afk.hero.process_heroes import (
    get_heroes, get_hero_contours)
from image_processing.processing.image_data import SegmentResult
from image_processing.models.model_attributes import (
    ASCENSION_STAR_LABELS, BORDER_MODEL_LABELS, FI_LABELS, ModelResult,
    SI_LABELS)
from image_processing.afk.roster.matrix import Matrix
from image_processing.afk.hero.hero_data import (
    DetectedHeroData, HeroImage, RosterData)
from image_processing.afk.roster.dimensions_object import DoubleCoordinates

if TYPE_CHECKING:
    from image_processing.models.yolov5.models.common import Detections

# Silence Module loading warnings from pytorch
warnings.filterwarnings("ignore")
FONT = cv2.FONT_HERSHEY_SIMPLEX
COLOR = (255, 255, 0)
THICKNESS = 2
IMAGES: List[np.ndarray] = []


def detect_features(roster_image: np.ndarray, debug_raw: bool = None):
    """
    Detect AFK Arena heroes from a roster screenshot and for each hero detect
        "FI", "SI", "Ascension", and "hero Name"
    Args:
        roster_image: image to run segmentation and detection on

        debug_raw: flag to add raw values for SI, FI and Ascension detection
            to return dictionary
    """

    if debug_raw is None:
        if GV.verbosity(1):
            debug_raw = True
        else:
            debug_raw = False

    lower_hsv = np.array([0, 0, 0])
    upper_hsv = np.array([179, 255, 192])

    hsv_range = [lower_hsv, upper_hsv]
    blur_args = {"hsv_range": hsv_range}
    # Run HSV segmentation on hero roster to get hero
    segment_dict, segment_matrix = get_heroes(roster_image, blur_args)

    detected_hero_data: list[DetectedHeroData] = []
    for _pseudo_segment_name, segment_info in segment_dict.items():
        hero_matches = GV.IMAGE_DB.search(segment_info)

        best_hero_match = hero_matches.best()
        best_match_info = GV.IMAGE_DB.hero_lookup[best_hero_match.name].first()

        detected_hero_result = detect_attributes(best_match_info, segment_info)
        detected_hero_data.append(detected_hero_result)

       # When debuggin Draw hero info on image
        if GV.verbosity(1):
            label_hero_feature(roster_image, segment_info,
                               detected_hero_result, segment_matrix)

    return RosterData(detected_hero_data, segment_matrix)


def label_hero_feature(roster_image: np.ndarray,
                       segment_info: SegmentResult,
                       detected_hero_result: DetectedHeroData,
                       hero_matrix: Matrix):
    """
    Write hero data such as FI/SI/Stars onto the roster image those attributes
        were derived from

    Args:
        roster_image (np.ndarray): roster of heroes
        segment_info (processing.SegmentResult): class with info describing the
            location of the detected_hero_results in the roster_image
        detected_hero_result (DetectedHeroData): data about a hero in the
            'roster_image' generated by 'detect_attributes'
        hero_matrix (matrix.matrix): matrix of hero data in the same horizontal
            and vertical order they were detected in
    """

    font_scale = 0.5 * (hero_matrix.get_avg_width()/100)

    result = str(detected_hero_result)

    hero_pixel_coordinate = (segment_info.segment_location.dimensions.x,
                             segment_info.segment_location.dimensions.y)
    text_size = cv2.getTextSize(result, FONT, font_scale, THICKNESS)
    height = text_size[0][1]
    bottom_left_coordinate = (hero_pixel_coordinate[0],
                              hero_pixel_coordinate[1] + round(5 * height))

    cv2.putText(roster_image, result, bottom_left_coordinate, FONT,
                abs(font_scale), COLOR, THICKNESS, cv2.LINE_AA)


def detect_furniture(detected_furnitures: DataFrame):
    """_summary_

    Args:
        detected_furniture (DataFrame): _description_

    Returns:
        _type_: _description_
    """

    furniture_result = ModelResult("0", 0)

    if len(detected_furnitures) > 0:
        best_furniture_match = detected_furnitures.sort_values(
            "confidence").iloc[0]
        best_furniture_label = FI_LABELS[best_furniture_match["class"]]

        if best_furniture_match["confidence"] >= 0.85:
            furniture_result = ModelResult(
                best_furniture_label, best_furniture_match["confidence"])
    return furniture_result


def detect_signature_item(detected_signature_items: DataFrame):
    """_summary_

    Args:
        detected_signature_items (DataFrame): _description_

    Returns:
        _type_: _description_
    """
    signature_item_result = ModelResult("0", 0)

    if len(detected_signature_items) > 0:
        best_signature_item_match = detected_signature_items.sort_values(
            "confidence", ascending=False).iloc[0]
        best_signature_item_label = (
            SI_LABELS[best_signature_item_match["class"]])

        if best_signature_item_match["confidence"] >= 0.85:
            signature_item_result = ModelResult(
                best_signature_item_label,
                best_signature_item_match["confidence"])
    return signature_item_result


def detect_ascension(detected_ascension_stars: DataFrame,
                     test_image: np.ndarray):
    """_summary_

    Args:
        detected_ascension_stars (DataFrame): _description_
        test_image (np.ndarray): _description_

    Returns:
        _type_: _description_
    """
    ascension_result = ModelResult("E", 0)
    best_match_coordinates = None
    if len(detected_ascension_stars) > 0:
        best_ascension_stars_match = detected_ascension_stars.sort_values(
            "confidence", ascending=False).iloc[0]
        best_match_coordinates = DoubleCoordinates(
            best_ascension_stars_match["xmin"],
            best_ascension_stars_match["xmax"],
            best_ascension_stars_match["ymin"],
            best_ascension_stars_match["ymax"])

        best_ascension_stars_label = ASCENSION_STAR_LABELS[
            best_ascension_stars_match["class"]]

        ascension_result = ModelResult(
            best_ascension_stars_label,
            best_ascension_stars_match["confidence"])

        if ascension_result.score < 0.75:
            # pylint: disable=not-callable
            raw_detected_ascension_borders: Dict = GV.ASCENSION_BORDER_MODEL(
                test_image)

            detected_ascension_borders: Instances = (
                raw_detected_ascension_borders["instances"])

            ascension_border_labels: List[int] = (
                detected_ascension_borders.pred_classes.cpu().tolist())
            ascension_border_scores: List[int] = (
                detected_ascension_borders.scores.cpu().tolist())

            ascension_border_results: List[ModelResult] = []

            for ascension_border_index, ascension_border_class_label in (
                    enumerate(ascension_border_labels)):
                ascension_border_score = (
                    ascension_border_scores[ascension_border_index])
                ascension_border_result = ModelResult(
                    BORDER_MODEL_LABELS[ascension_border_class_label],
                    ascension_border_score)
                ascension_border_results.append(ascension_border_result)

            ascension_border_results.sort(
                key=lambda model_result: model_result.score)

            if len(ascension_border_results) > 0:
                best_ascension_border = ascension_border_results[0]
                ascension_result = best_ascension_border

    return ascension_result, best_match_coordinates


def detect_engraving(ascension_result: ModelResult, image: np.ndarray,
                     star_coordinates: DoubleCoordinates):
    """_summary_

    Args:
        ascension_result (ModelResult): _description_
        image (np.ndarray): _description_
        star_coordinates (DoubleCoordinates): _description_

    Returns:
        _type_: _description_
    """
    engraving_result = ModelResult("0", 0)
    print(ascension_result.label)
    if ascension_result.label in ASCENSION_STAR_LABELS.inverse:
        pass
        # temp_image = image[star_coordinates.y1:star_coordinates.y2,
        #                    star_coordinates.x1:star_coordinates.x2]
        # hsv_range = [
        #     np.array([0, 0, 178]), np.array([179, 255, 255])]
        # # new_image = blur_image(temp_image, dilate=True, hsv_range=hsv_range)
        # # print(new_image.shape)
        # contour_dict = get_hero_contours(
        #     temp_image, size_allowance_boundary=0.15, hsv_range=hsv_range)
        # mask = np.zeros(temp_image.shape, np.uint8)

        # for counter_name, contour_dimension_object in contour_dict.items():
        #     cv2.drawContours(
        #         mask, [contour_dimension_object.raw_data], -1, 255, -1)

        # display_image([temp_image, mask], display=True)

        # (hue_min = 0 , saturation_min = 0, value_min = 178), (hue_max = 179 , saturation_max = 255, value_max = 255)

        # Load the image into an array: image
        # crop image if necessary - required for the original test image because of wide left/right borders, but new image doesn't have borders
        # image = image[100:560, 368:864, :]

        # show the cropped image

        # Z = temp_image.reshape((-1,3))

        # # convert to np.float32
        # Z = np.float32(Z)

        # # define criteria, number of clusters(K) and apply kmeans()
        # criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
        # K = 2
        # ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)

        # # Now convert back into uint8, and make original image
        # center = np.uint8(center)
        # res = center[label.flatten()]
        # res2 = res.reshape((temp_image.shape))

        # display_image([temp_image, res2], display=True)
        # print(best_ascension_stars_match)
        # print(temp_image.shape)
        # cv2.rectangle(temp_image,
        #               best_match_coordinates.vertex1(),
        #               best_match_coordinates.vertex2(),
        #               255, 1)

        # global IMAGES
        # IMAGES.append(temp_image)
        # # display_image(temp_image, display=True)
        # if len(IMAGES) % 5 == 0:
        #     display_image(IMAGES, display=True)
        #     IMAGES = []

    return engraving_result


def detect_attributes(hero_image_info: HeroImage, segment_info: SegmentResult):
    """
    Detect hero features such as FI, SI, Stars and ascension level using'
        custom trained yolov5 and detectron2 image recognition models

    Args:
        hero_image_info (HeroImage): A wrapper around an image detected from
            the Flann image database that includes the image itself, the image
            name and the location the image was loaded from
        segment_info (processing.SegmentResult): class with info describing the
            location of the detected_hero_results in the roster_image
    Returns:
        [type]: [description]
    """

    test_img = segment_info.image[..., ::-1]

    # pylint: disable=not-callable
    raw_model_results: "Detections" = GV.FI_SI_STAR_MODEL([test_img], size=416)
    labeled_model_results: DataFrame = raw_model_results.pandas().xyxy[0]

    detected_furniture: DataFrame = labeled_model_results.loc[
        labeled_model_results['class'].isin(FI_LABELS.keys())]
    detected_ascension_stars: DataFrame = labeled_model_results.loc[
        labeled_model_results['class'].isin(ASCENSION_STAR_LABELS.keys())]
    detected_signature_items: DataFrame = labeled_model_results.loc[
        labeled_model_results['class'].isin(SI_LABELS.keys())]

    furniture_result = detect_furniture(detected_furniture)
    ascension_result, star_coordinates = detect_ascension(
        detected_ascension_stars, test_img)
    signature_item_result = detect_signature_item(detected_signature_items)
    engraving_result = detect_engraving(
        ascension_result, test_img, star_coordinates)

    hero_data = DetectedHeroData(hero_image_info.name, signature_item_result,
                                 furniture_result, ascension_result,
                                 engraving_result, segment_info.image)
    return hero_data
